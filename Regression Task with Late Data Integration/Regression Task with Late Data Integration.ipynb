{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Task with Late Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas and numpy libraries for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import the metric to calculate mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Import Tensorflow libraries for deep learning\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model to use with only one view\n",
    "def init_model(input_dim, learning_rate, epochs, momentum, neurons, trainable=True):\n",
    "    input = Input(shape=(input_dim,))\n",
    "    layer = Dense(neurons, activation='sigmoid',\n",
    "    kernel_constraint=max_norm(3)) (input)\n",
    "    layer = Dropout(rate=0.6) (layer)\n",
    "    layer = Dense(neurons, activation='sigmoid',\n",
    "    kernel_constraint=max_norm(3)) (layer)\n",
    "    layer = Dropout(rate=0.6) (layer)\n",
    "    predictions = Dense(1, activation='linear') (layer)\n",
    "    model = Model(inputs=input, outputs=predictions)\n",
    "    rms = SGD(lr=learning_rate, decay=learning_rate / epochs,\n",
    "    momentum=momentum)\n",
    "    model.trainable = trainable\n",
    "    if (trainable) :\n",
    "        model.compile(loss='mean_squared_error', optimizer=rms, metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network to use in a multi=view fashion\n",
    "def init_multi_model(input_dim,input_dim2, learning_rate, epochs, momentum, neurons, metabolic_fluxes_layer, \n",
    "                     gene_expression_layer):\n",
    "    metabolic_fluxes_input = Input(shape=(input_dim,))\n",
    "    gene_expression_input = Input(shape=(input_dim2,))\n",
    "    comb_layer = Concatenate()([metabolic_fluxes_layer(metabolic_fluxes_input), \n",
    "                            gene_expression_layer(gene_expression_input)])\n",
    "    comb_layer = Dense(neurons, activation='sigmoid', kernel_constraint=max_norm(3)) (comb_layer)\n",
    "    predictions = Dense(1, activation='linear') (comb_layer)\n",
    "    model = Model(inputs=[metabolic_fluxes_input, gene_expression_input], outputs=predictions)\n",
    "    rms = SGD(lr=learning_rate, decay=learning_rate / epochs, momentum=momentum)\n",
    "    model.compile(loss='mean_squared_error', optimizer=rms, metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the proportion of data to be used as the test set\n",
    "percent_test = 0.3\n",
    "# Import flux data\n",
    "metabolic_data = pd.read_csv('fluxes.csv', encoding='utf-8')\n",
    "# Disregard null fluxes\n",
    "metabolic_data = metabolic_data.loc[:, (metabolic_data.abs() >= 1e-7).any(axis=0)]\n",
    "# Import gene expression data\n",
    "gene_expression_data = pd.read_csv('gene_expression_data.csv', encoding='utf-8')\n",
    "X = gene_expression_data[gene_expression_data.columns[:-1]]\n",
    "Y = gene_expression_data[gene_expression_data.columns[-1]]\n",
    "# Split gene expression data into training and test sets\n",
    "gene_expression_train, gene_expression_test, Y_train, Y_test = train_test_split(X, Y, test_size=percent_test, shuffle=False)\n",
    "# Split flux data into training and test sets\n",
    "metabolic_fluxes_train, metabolic_fluxes_test = train_test_split(X, test_size=percent_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature scaling to normalize the training data\n",
    "stdscaler_f = StandardScaler()\n",
    "stdscaler_g = StandardScaler()\n",
    "metabolic_fluxes_train = stdscaler_f.fit_transform(metabolic_fluxes_train)\n",
    "gene_expression_train = stdscaler_g.fit_transform(gene_expression_train)\n",
    "# Normalize the test sets with the same parametric values as the training sets\n",
    "metabolic_fluxes_test = stdscaler_f.transform(metabolic_fluxes_test)\n",
    "gene_expression_test = stdscaler_g.transform(gene_expression_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs, batches, learning rate and validation set split size\n",
    "epochs = 6000\n",
    "batches = 256\n",
    "lrate = 0.005\n",
    "validation = 0.2\n",
    "lrate2 = 0.05\n",
    "epochs2 = 500\n",
    "# Define the stochastic gradient descent algorithm and the early stopping strategy to prevent overfitting\n",
    "rms = SGD(lr=lrate , decay=lrate / epochs, momentum=0.75)\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=15000, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize separate single=view models for the gene expression and flux datasets\n",
    "model_gene_expression = init_model(gene_expression_train.shape[1], lrate, 3000, 0.75, 1000)\n",
    "model_metabolic_fluxes = init_model(metabolic_fluxes_train.shape[1], lrate, 3000, 0.75,1000)\n",
    "# Fit both the learning models on the training data\n",
    "model_gene_expression.fit(x=gene_expression_train, y=Y_train, epochs=epochs, batch_size=batches, \n",
    "                          validation_split=validation, callbacks=[earlyStopping], verbose=0)\n",
    "model_metabolic_fluxes.fit(x=metabolic_fluxes_train, y=Y_train, epochs=epochs, batch_size=batches, \n",
    "                           validation_split=validation, callbacks=[earlyStopping], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last layer from each single view model\n",
    "model_gene_expression.layers.pop()\n",
    "model_gene_expression.layers.pop()\n",
    "model_gene_expression.outputs = [model_gene_expression.layers[-1].output]\n",
    "model_metabolic_fluxes.layers.pop()\n",
    "model_metabolic_fluxes.layers.pop()\n",
    "model_metabolic_fluxes.outputs = [model_metabolic_fluxes.layers[-1].output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the multi=modal model\n",
    "multi_modal_model = init_multi_model(metabolic_fluxes_train.shape[1], gene_expression_train.shape[1], lrate2, epochs2, \n",
    "                                     0.75, 15, model_metabolic_fluxes, model_gene_expression)\n",
    "# Fit the multi=modal model using training samples\n",
    "multi_modal_model.fit(x=[metabolic_fluxes_train, gene_expression_train], y=Y_train, epochs=epochs2, batch_size=batches, \n",
    "                      validation_split=validation, verbose=0)\n",
    "# Generate predictions for the test set samples\n",
    "predictions = multi_modal_model.predict([metabolic_fluxes_test, gene_expression_test])\n",
    "# Print mean squared error\n",
    "print('MSE: ', mean_squared_error(predictions, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
